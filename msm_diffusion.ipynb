{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up environment\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sci\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "# %matplotlib inline\n",
    "import new_colormaps as cm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import itertools as it\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "import pyemma\n",
    "pyemma.__version__\n",
    "\n",
    "import pyemma.coordinates as coor\n",
    "import pyemma.msm as msm\n",
    "import pyemma.plots as mplt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "#import shapely.geometry as geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful functions\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cosd(deg):\n",
    "    return np.cos(deg/180. * np.pi)\n",
    "\n",
    "def sind(deg):\n",
    "    return np.sin(deg/180. * np.pi)\n",
    "\n",
    "def xyz2fracM(crystal_prms):\n",
    "    a = crystal_prms['a']\n",
    "    b = crystal_prms['b']\n",
    "    c = crystal_prms['c']\n",
    "    alpha = crystal_prms['alpha']\n",
    "    beta = crystal_prms['beta']\n",
    "    gamma = crystal_prms['gamma']\n",
    "    v = np.sqrt(1-cosd(alpha)**2-cosd(beta)**2-cosd(gamma)**2 + 2*cosd(alpha)* cosd(beta)*cosd(gamma))\n",
    "    r1 = [1./a, -cosd(gamma)/a/sind(gamma), (cosd(alpha)*cosd(gamma)-cosd(beta)) / a/v/sind(gamma)]\n",
    "    r2 = [0, 1./b/sind(gamma), (cosd(beta)*cosd(gamma)-cosd(alpha)) / b/v/sind(gamma)]\n",
    "    r3 = [0, 0, sind(gamma)/c/v]\n",
    "    M = np.array([r1, r2, r3])\n",
    "    return M\n",
    "\n",
    "def frac2xyzM(crystal_prms):\n",
    "    a = crystal_prms['a']\n",
    "    b = crystal_prms['b']\n",
    "    c = crystal_prms['c']\n",
    "    alpha = crystal_prms['alpha']\n",
    "    beta = crystal_prms['beta']\n",
    "    gamma = crystal_prms['gamma']\n",
    "    v = np.sqrt(1-cosd(alpha)**2-cosd(beta)**2-cosd(gamma)**2 + 2*cosd(alpha)* cosd(beta)*cosd(gamma))\n",
    "    r1 = [a, b*cosd(gamma), c*cosd(beta)]\n",
    "    r2 = [0, b*sind(gamma), c*(cosd(alpha)-cosd(beta)*cosd(gamma))/sind(gamma)]\n",
    "    r3 = [0, 0, c*v/sind(gamma)]\n",
    "    M = np.array([r1, r2, r3])\n",
    "    return M\n",
    "\n",
    "def wrap(x, y, z, Mfwd, Mrev):\n",
    "    fxyz = np.dot(Mfwd, np.array([x, y, z]))\n",
    "    fxyz_ = fxyz % 1\n",
    "    wrapped = np.dot(Mrev, np.array(fxyz_))\n",
    "    wrapped = np.around(wrapped, 8)\n",
    "    return wrapped \n",
    "\n",
    "\n",
    "# # Function to read the dump file\n",
    "\n",
    "def read_file(infiles, frames):\n",
    "    t = []\n",
    "    xyz = []\n",
    "    for infile in infiles:\n",
    "        with open(infile, 'r') as fin:\n",
    "            for line in fin:\n",
    "              if len(t)<=frames:\n",
    "                line_chunks = line.split()\n",
    "                if line_chunks[0] != '#':\n",
    "                    try:\n",
    "                        ind, x, y, z = map(float, line_chunks)\n",
    "                        ind = int(line_chunks[0])\n",
    "                        xyz.append([x, y, z])\n",
    "                    except:\n",
    "                        simtime, N = map(int, line_chunks)\n",
    "                        t.append(float(simtime))\n",
    "\n",
    "    # Convert timestep to time\n",
    "    #fs2ps = 0.001\n",
    "    #t = (np.array(t) - t[0]) * timestep_fs * fs2ps\n",
    "\n",
    "    # Get number of frames and reshape data array\n",
    "    numframes =  len(xyz) // N\n",
    "    xyz = np.reshape(xyz, (numframes, N, 3))\n",
    "\n",
    "    if debug:\n",
    "        print (\"Finished read_file\")\n",
    "    return numframes, N, 3, xyz\n",
    "\n",
    "\n",
    "def wrapcoords(alldata, Mfwd, Mrev):\n",
    "    N, trj, dim = np.shape(alldata)\n",
    "    alldataT= np.transpose(alldata)\n",
    "    xyz_wrap_T = np.empty((dim, trj, N))\n",
    "    for i in range(trj):\n",
    "        frac_T = np.dot(Mfwd, alldataT[:,i,:])\n",
    "        \n",
    "        ## offset unit cell\n",
    "        #frac_T += np.transpose([[.5, .5, 0]])\n",
    "        \n",
    "        # wrap unit cell coordinates\n",
    "        frac_wrap_T = frac_T % 1\n",
    "\n",
    "        # convert fractional to cartesian coords\n",
    "        xyz_wrap_T[:, i, :] = np.dot(Mrev, frac_wrap_T)\n",
    "\n",
    "    xyz_wrap = np.transpose(xyz_wrap_T)\n",
    "    \n",
    "    #if debug:\n",
    "    #    print (\"finished wrapcoords\")\n",
    "    return xyz_wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read dumpfile to obtain data\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished read_file\n",
      "(4000, 260, 3)\n"
     ]
    }
   ],
   "source": [
    "debug = True\n",
    "timestep_fs = 1\n",
    "\n",
    "adsorbate = 'butane'\n",
    "trjs = 260  # 200, 260, 270\n",
    "T = 298\n",
    "Nframes = 4000\n",
    "dt = .001  # convert frame indices to ns\n",
    "\n",
    "\n",
    "### ABENAKI\n",
    "basedir = '/home/vargaslo/ws/LAMMPS_MD/MSD_analyzed/298K'\n",
    "sourcedir = os.path.join(basedir, '{}/{}/MDSim_{}K'.format(adsorbate, trjs, T))\n",
    "\n",
    "### ANISHINAABE\n",
    "sourcedir=''\n",
    "\n",
    "\n",
    "dumpfile = os.path.join(sourcedir, 'lammps_3_extend.dump')\n",
    "Nframes, _, Ndims, mydat_u_orig = read_file([dumpfile], Nframes)\n",
    "print (np.shape(mydat_u_orig))\n",
    "\n",
    "activedir = os.path.join('{}_N{}_T{}_ff{}'.format(adsorbate, trjs, T, Nframes))\n",
    "if not os.path.exists(activedir):\n",
    "    os.makedirs(activedir)\n",
    "\n",
    "\n",
    "crystal = {}\n",
    "crystal['a'] = 39.97\n",
    "crystal['b'] = 40.00\n",
    "crystal['c'] = 16.58*2\n",
    "crystal['alpha'] = 90\n",
    "crystal['beta'] = 90\n",
    "crystal['gamma'] = 120\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class data:\n",
    "    def __init__(self, origdata, crystal_prms):\n",
    "        self.origdata = origdata\n",
    "        self.crystal_prms = crystal_prms        \n",
    "        self.Mfwd = xyz2fracM(crystal_prms)\n",
    "        self.Mrev = frac2xyzM(crystal_prms)      \n",
    "        self.Nframes, self.Ntrjs, self.Ndims = np.shape(self.origdata)\n",
    "    \n",
    "    def unwrapped(self):\n",
    "        return self.origdata\n",
    "    \n",
    "    def wrapped(self):\n",
    "        return wrapcoords(self.origdata, self.Mfwd, self.Mrev)\n",
    "\n",
    "    #-------------------------------------------------\n",
    "    # create list of ndarrays(trjs,dims) using indices\n",
    "    #-------------------------------------------------\n",
    "\n",
    "    def get_xyz_region(self, hexregions=1):  # hexregions=1 is to split meso/micro\n",
    "        xyz = self.unwrapped()\n",
    "        xyz_wrap = self.wrapped()\n",
    "\n",
    "        # check if inside circle\n",
    "        P1 = np.dot(self.Mrev, np.array([0.0, 0.0, 0]))   #   P4------P8-------P3\n",
    "        P2 = np.dot(self.Mrev, np.array([1.0, 0.0, 0]))   #    \\        \\        \\\n",
    "        P3 = np.dot(self.Mrev, np.array([1.0, 1.0, 0]))   #     \\   uc   \\   uc   \\\n",
    "        P4 = np.dot(self.Mrev, np.array([0.0, 1.0, 0]))   #      \\        \\        \\\n",
    "        P5 = np.dot(self.Mrev, np.array([0.0, 0.5, 0]))   #       P5-------P7------P9\n",
    "        P6 = np.dot(self.Mrev, np.array([0.5, 0.0, 0]))   #        \\        \\        \\\n",
    "        P7 = np.dot(self.Mrev, np.array([0.5, 0.5, 0]))   #         \\   uc   \\   uc   \\\n",
    "        P8 = np.dot(self.Mrev, np.array([0.5, 1.0, 0]))   #          \\        \\        \\\n",
    "        P9 = np.dot(self.Mrev, np.array([1.0, 0.5, 0]))   #           P1-------P6------P2\n",
    "\n",
    "        region = np.ones((self.Nframes, self.Ntrjs, 1), dtype=int)  # default to region 1 (micro)\n",
    "                                                                    # region 2 is meso outer, and so on until hexregions+1\n",
    "\n",
    "        for i in range(hexregions):\n",
    "            radius = 17 * np.sqrt(1 - 1.*i/hexregions)\n",
    "            for P in [P1, P2, P3, P4]:\n",
    "                s2 = np.sum(np.power(xyz_wrap - P, 2)[:,:,0:2], axis=2)\n",
    "                region[:,:, 0] +=  (s2 <= radius**2)*1  # regions are numbered increasing to the center of channel\n",
    "\n",
    "        #combined = np.concatenate((xyz, region, xyz_wrap), axis=2)\n",
    "        reg1 = region==1\n",
    "        reg2 = region==2\n",
    "        \n",
    "        microxyz_w = xyz_wrap*reg1\n",
    "        mesoxyz_w = xyz_wrap*reg2\n",
    "    \n",
    "        combined = np.concatenate((xyz, region, microxyz_w), axis=2)\n",
    "\n",
    "        return combined\n",
    "\n",
    "        \n",
    "    def group_ind(self):\n",
    "        xyzdata = self.get_xyz_region()\n",
    "        indices = {}\n",
    "        indices[1] = []\n",
    "        indices[2] = []\n",
    "            \n",
    "        first = 0\n",
    "        last = 0\n",
    "        for p in range(self.Ntrjs):\n",
    "            for i,v in enumerate(itertools.groupby(xyzdata[:,p,:], lambda x: x[3])):\n",
    "                key, group = v\n",
    "                N = len(list(group))\n",
    "                last = first + N\n",
    "                indices[int(key)].append((first, last))\n",
    "            \n",
    "                first = last\n",
    "        return indices\n",
    "\n",
    "\n",
    "    def micro_u(self, region=1):\n",
    "        xyz = self.unwrapped()\n",
    "        xyz_ = np.reshape(xyz, (self.Nframes * self.Ntrjs, self.Ndims), order='F')\n",
    "        data = []\n",
    "        for i in self.group_ind()[region]:\n",
    "            ff, lf = i\n",
    "            tmp = xyz_[ff:lf, :]\n",
    "            data.append(tmp)\n",
    "        return data\n",
    "\n",
    "    def micro_w(self, region=1):\n",
    "        xyz = self.wrapped()\n",
    "        xyz_ = np.reshape(xyz, (self.Nframes * self.Ntrjs, self.Ndims), order='F')\n",
    "        data = []\n",
    "        for i in self.group_ind()[region]:\n",
    "            ff, lf = i\n",
    "            tmp = xyz_[ff:lf, :]\n",
    "            data.append(tmp)\n",
    "        return data\n",
    "\n",
    "    def meso_u(self, region=2):\n",
    "        xyz = self.unwrapped()\n",
    "        xyz_ = np.reshape(xyz, (self.Nframes * self.Ntrjs, self.Ndims), order='F')\n",
    "        data = []\n",
    "        for i in self.group_ind()[region]:\n",
    "            ff, lf = i\n",
    "            tmp = xyz_[ff:lf, :]\n",
    "            data.append(tmp)\n",
    "        return data\n",
    "        \n",
    "    def meso_w(self, region=2):\n",
    "        xyz = self.wrapped()\n",
    "        xyz_ = np.reshape(xyz, (self.Nframes * self.Ntrjs, self.Ndims), order='F')\n",
    "        data = []\n",
    "        for i in self.group_ind()[region]:\n",
    "            ff, lf = i\n",
    "            tmp = xyz_[ff:lf, :]\n",
    "            data.append(tmp)\n",
    "        return data\n",
    "\n",
    "    def xyz2sz(self):\n",
    "        xyz = self.wrapped()\n",
    "        # check if inside circle\n",
    "        P1 = np.dot(self.Mrev, np.array([0.0, 0.0, 0]))   #   P4------P8-------P3\n",
    "        P2 = np.dot(self.Mrev, np.array([1.0, 0.0, 0]))   #    \\        \\        \\\n",
    "        P3 = np.dot(self.Mrev, np.array([1.0, 1.0, 0]))   #     \\   uc   \\   uc   \\\n",
    "        P4 = np.dot(self.Mrev, np.array([0.0, 1.0, 0]))   #      \\        \\        \\\n",
    "        P5 = np.dot(self.Mrev, np.array([0.0, 0.5, 0]))   #       P5-------P7------P9\n",
    "        P6 = np.dot(self.Mrev, np.array([0.5, 0.0, 0]))   #        \\        \\        \\\n",
    "        P7 = np.dot(self.Mrev, np.array([0.5, 0.5, 0]))   #         \\   uc   \\   uc   \\\n",
    "        P8 = np.dot(self.Mrev, np.array([0.5, 1.0, 0]))   #          \\        \\        \\\n",
    "        P9 = np.dot(self.Mrev, np.array([1.0, 0.5, 0]))   #           P1-------P6------P2\n",
    "\n",
    "\n",
    "        s1 = np.sqrt(np.sum((xyz[:,:,0:2]-P1[np.newaxis, np.newaxis, 0:2])**2, axis=2))\n",
    "        s2 = np.sqrt(np.sum((xyz[:,:,0:2]-P2[np.newaxis, np.newaxis, 0:2])**2, axis=2))\n",
    "        s3 = np.sqrt(np.sum((xyz[:,:,0:2]-P3[np.newaxis, np.newaxis, 0:2])**2, axis=2))\n",
    "        s4 = np.sqrt(np.sum((xyz[:,:,0:2]-P4[np.newaxis, np.newaxis, 0:2])**2, axis=2))\n",
    "        s0 = np.minimum(s1, s2)\n",
    "        s0 = np.minimum(s0, s3)\n",
    "        s0 = np.minimum(s0, s4)\n",
    "\n",
    "        # find points in microchannel\n",
    "        tmp = s0>17\n",
    "        \n",
    "        s = tmp*s0\n",
    "        z = tmp*xyz[:,:,2]\n",
    "\n",
    "        sz = np.zeros((self.Nframes, self.Ntrjs, 2))\n",
    "        sz[:,:,0] = s\n",
    "        sz[:,:,1] = z\n",
    "        \n",
    "        return sz\n",
    "    \n",
    "    def tica_sz(self, region=1):  # region 1 is microchannel\n",
    "        sz = self.xyz2sz()\n",
    "        sz_ = np.reshape(sz, (self.Nframes * self.Ntrjs, 2), order='F')\n",
    "        \n",
    "#        xyz = self.wrapped()\n",
    "#        xyz_ = np.reshape(xyz, (self.Nframes * self.Ntrjs, self.Ndims), order='F')\n",
    "        data = []\n",
    "        for i in self.group_ind()[region]:\n",
    "            ff, lf = i\n",
    "#            tmp = xyz_[ff:lf, :]\n",
    "            tmp = sz_[ff:lf, :]\n",
    "#            tmp2 = np.zeros((np.shape(tmp)[0], 2))\n",
    "#            tmp2[:,0] = np.sqrt(tmp[:,0]**2 + tmp[:,1]**2)\n",
    "#            tmp2[:,1] = tmp[:,2]\n",
    "            data.append(tmp)\n",
    "            \n",
    "#        return list(np.swapaxes(sz, 0, 1))\n",
    "        return data\n",
    "        \n",
    "\n",
    "x = data(mydat_u_orig, crystal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12466\n"
     ]
    }
   ],
   "source": [
    "# use this to visualize data\n",
    "if 0:\n",
    "    plt.close('all')\n",
    "    for i in x.tica_sz():\n",
    "        plt.plot(i[:,0], i[:,1], ls='', marker=',')\n",
    "    \n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.show()\n",
    "    \n",
    "print (len(x.tica_sz()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = x.tica_sz()\n",
    "\n",
    "def longest(Y):\n",
    "    # get index of longest trajectory\n",
    "    longest = 0\n",
    "    for i,v in enumerate(Y):\n",
    "        if len(v)>longest:\n",
    "            longest = len(v)\n",
    "            index = i\n",
    "    return i, longest\n",
    "\n",
    "maxduration_ind, maxduration = longest(Y)\n",
    "\n",
    "if 0:  # Show free energy?\n",
    "    plt.close('all')\n",
    "    pyemma.plots.plot_free_energy(np.vstack(Y)[:,0], np.vstack(Y)[:,1], cmap=cm.viridis)\n",
    "    \n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.xlabel('Distance from mesochannel axis (A)')\n",
    "    plt.ylabel('Z-distance (A)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretize trajectories\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('stride ', 10)\n",
      "18-04-16 12:40:52 pyemma.coordinates.clustering.kmeans.KmeansClustering[0] INFO     Cluster centers converged after 5 steps.\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 512\n",
    "\n",
    "stride = max(1, (Nframes*trjs)//100000)\n",
    "print ('stride ', stride)\n",
    "\n",
    "clustering = coor.cluster_kmeans(Y, k=n_clusters, max_iter=200, stride=stride, fixed_seed=True)\n",
    "dtrajs = clustering.dtrajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dtraj_fig(dtrajs):\n",
    "    \n",
    "    # show discrete trajectory time series\n",
    "    plt.close('all')\n",
    "    plt.figure()\n",
    "    plt.plot(dtrajs[maxduration_ind], marker='.', ls='-', lw=.1)\n",
    "    plt.ylabel('cluster')\n",
    "    plt.xlabel('frame index')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    pyemma.plots.plot_free_energy(np.vstack(Y)[:,0], np.vstack(Y)[:,1], cmap=cm.viridis)\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.xlabel('Distance from mesochannel axis (A)')\n",
    "    plt.ylabel('Z-distance (A)')\n",
    "    plt.scatter(clustering.clustercenters[:,0], clustering.clustercenters[:,1], c='r')\n",
    "\n",
    "    plt.savefig('{}/dtrj0_{}.png'.format(activedir, n_clusters), dpit=144)\n",
    "    \n",
    "    return\n",
    "\n",
    "dtraj_fig(dtrajs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implied timescales\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "its = msm.timescales_msm(dtrajs, nits=7, n_jobs=-1, lags=np.linspace(1, maxduration/3, 4, dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(7,10))\n",
    "\n",
    "plt.subplot(211)\n",
    "mplt.plot_implied_timescales(its, ylog=True, units='steps', linewidth=2)\n",
    "\n",
    "plt.subplot(212)\n",
    "mplt.plot_implied_timescales(its, ylog=False, units='steps', linewidth=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('{}/its_{}.png'.format(activedir, n_clusters), dpi=144)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSM\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "msm_lag = Nframes//3\n",
    "msm_lag = 10\n",
    "\n",
    "M = msm.estimate_markov_model(dtrajs, msm_lag, sparse=False)\n",
    "print (msm_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fraction of states used = ', 1.0)\n",
      "('fraction of counts used = ', 1.0)\n"
     ]
    }
   ],
   "source": [
    "print ('fraction of states used = ', M.active_state_fraction)\n",
    "print ('fraction of counts used = ', M.active_count_fraction)\n",
    "\n",
    "def mapcc(M):\n",
    "    out = {}\n",
    "    for i,v in enumerate(M.largest_connected_set):\n",
    "        out[i] = {}\n",
    "        out[i]['orig'] = v\n",
    "        out[i]['cc'] = clustering.clustercenters[v]\n",
    "    return out\n",
    "\n",
    "mapped = mapcc(M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test MSM\n",
    "M = msm.bayesian_markov_model(dtrajs, msm_lag, nsamples=100)  # default nsamples is 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vargaslo/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: RuntimeWarning: divide by zero encountered in log10\n",
      "/home/vargaslo/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:11: RuntimeWarning: divide by zero encountered in log10\n"
     ]
    }
   ],
   "source": [
    "def show_trans_mat(M):\n",
    "        \n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.imshow(np.log10(M.transition_matrix), cmap=cm.viridis, vmin=-5, vmax=-1, interpolation='nearest')\n",
    "    #plt.imshow(np.log10(M.sample_mean('transition_matrix')), cmap=cm.viridis, vmin=-5, vmax=-1, interpolation='nearest')\n",
    "    plt.gca().set_axis_bgcolor('k')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('{}/trans_matrix_clusters{}_lag{}.png'.format(activedir, n_clusters, msm_lag), dpi=144)\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.imshow(np.log10(M.count_matrix_active), cmap=cm.viridis, vmin=0, vmax=2, interpolation='nearest')\n",
    "    plt.ylim(0,24)\n",
    "    plt.xlim(0,24)\n",
    "    plt.gca().set_axis_bgcolor('k')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('{}/count_matrix_clusters{}_lag{}.png'.format(activedir, n_clusters, msm_lag), dpi=144)\n",
    "\n",
    "    return\n",
    "\n",
    "plt.close('all')\n",
    "show_trans_mat(M)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral analysis\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   i     eigenval          its        ratio\n",
      "   2       0.9958       2.3505       2.4139\n",
      "   3       0.9898       0.9737       1.4597\n",
      "   4       0.9851       0.6671       1.7485\n",
      "   5       0.9741       0.3815       1.0292\n",
      "   6       0.9734       0.3707       1.5399\n",
      "   7       0.9593       0.2407       1.8423\n",
      "   8       0.9263       0.1307       1.1122\n",
      "   9       0.9184       0.1175       1.0799\n",
      "  10       0.9122       0.1088       1.9738\n",
      "  11       0.8341       0.0551       1.1025\n",
      "  12       0.8187       0.0500       1.1280\n",
      "  13       0.7980       0.0443       1.0735\n",
      "  14       0.7848       0.0413       1.5234\n",
      "  15       0.6914       0.0271       1.1067\n",
      "  16       0.6647       0.0245       1.3247\n",
      "  17       0.5821       0.0185       1.2599\n",
      "  18       0.5057       0.0147       1.1358\n",
      "  19       0.4610       0.0129       1.0532\n"
     ]
    }
   ],
   "source": [
    "# Show eigenvalue separation\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "plt.figure(figsize=(7,10))\n",
    "plt.subplot(211)\n",
    "tmpy = dt * M.timescales()\n",
    "tmpx = range(2, 2+len(tmpy))\n",
    "plt.plot(tmpx, tmpy,linewidth=0,marker='o')\n",
    "plt.ylabel('timescale (1 ns)'); \n",
    "plt.xlim(-0.5,18.5)\n",
    "plt.ylim(0,min(10, plt.ylim()[1]))\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "tmpy_ = M.timescales()[:-1]/M.timescales()[1:]\n",
    "tmpx_ = range(2, 2+len(tmpy_))\n",
    "plt.bar(tmpx_, tmpy_, width=.1)#, linewidth=0,marker='o')\n",
    "plt.axhline(2, c='r', ls='--')\n",
    "plt.ylabel('timescale separation'); \n",
    "plt.xlim(-0.5,18.5)\n",
    "plt.ylim(0, 5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('{}/eigenval_separation_clusters{}_lag{}.png'.format(activedir, n_clusters, msm_lag), dpi=144)\n",
    "\n",
    "print ('{:>4} {:>12} {:>12} {:>12}'.format('i', 'eigenval', 'its', 'ratio'))\n",
    "for i in range(18):\n",
    "    print ('{:4} {:>12.4f} {:>12.4f} {:>12.4f}'.format(i+2, M.eigenvalues()[i+1], dt*M.timescales()[i], M.timescales()[i]/M.timescales()[i+1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "tmpy = M.eigenvalues()\n",
    "tmpx = range(2, 2+len(tmpy))\n",
    "plt.bar(tmpx, tmpy, width=.2)\n",
    "plt.plot(tmpx, tmpy,linewidth=0,marker='o')\n",
    "plt.axhline(0, c='r')\n",
    "plt.ylabel('Eigenvalues'); \n",
    "plt.xlabel('Index'); \n",
    "plt.xlim(-0.5,124.5)\n",
    "#plt.ylim(0,min(10, plt.ylim()[1]))\n",
    "\n",
    "plt.savefig('{}/eigenvalues_clusters{}_lag{}.png'.format(activedir, n_clusters, msm_lag), dpi=144)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View eigenvectors\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_sampled_function(xall, yall, zall, ax=None, nbins=100, nlevels=20, cmap=cm.viridis, cbar=True, \n",
    "                          cbar_label=None, vmin=None, vmax=None):\n",
    "    # histogram data\n",
    "    xmin = np.amin(xall)\n",
    "    xmax = np.amax(xall)\n",
    "    dx = (xmax - xmin) / float(nbins)\n",
    "    ymin = np.amin(yall)\n",
    "    ymax = np.amax(yall)\n",
    "    dy = (ymax - ymin) / float(nbins)\n",
    "    # bin data\n",
    "    #eps = x\n",
    "    xbins = np.linspace(xmin - 0.5*dx, xmax + 0.5*dx, num=nbins)\n",
    "    ybins = np.linspace(ymin - 0.5*dy, ymax + 0.5*dy, num=nbins)\n",
    "    xI = np.digitize(xall, xbins)\n",
    "    yI = np.digitize(yall, ybins)\n",
    "    # result\n",
    "    z = np.zeros((nbins, nbins))\n",
    "    N = np.zeros((nbins, nbins))\n",
    "    # average over bins\n",
    "    for t in range(len(xall)):\n",
    "        z[xI[t], yI[t]] += zall[t]\n",
    "        N[xI[t], yI[t]] += 1.0\n",
    "    z /= N\n",
    "    # do a contour plot\n",
    "    extent = [xmin, xmax, ymin, ymax]\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    cf = ax.contourf(z.T, nlevels, extent=extent, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    if cbar:\n",
    "        cbar = plt.colorbar(cf)\n",
    "        if cbar_label is not None:\n",
    "            cbar.ax.set_ylabel(cbar_label)\n",
    "            \n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_sampled_density(xall, yall, zall, ax=None, nbins=100, cmap=cm.viridis, cbar=True, cbar_label=None, vmin=None, vmax=None):\n",
    "    return plot_sampled_function(xall, yall, zall, ax=ax, nbins=nbins, cmap=cmap, \n",
    "                                 cbar=cbar, cbar_label=cbar_label, vmin=vmin, vmax=vmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vargaslo/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:23: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "def show_eigenvec(first_n_ev):\n",
    "\n",
    "    def proj_ev():\n",
    "        proj_ev_all = []\n",
    "        for i in range(min(32,n_clusters)):\n",
    "            tmp_ = []\n",
    "            xx = []\n",
    "            yy = []\n",
    "            eigval = M.eigenvalues()[i]\n",
    "            eigvec = np.copy(M.eigenvectors_right()[:,i])\n",
    "            eigvec = np.append(eigvec, 0)\n",
    "            for dtraj_mapped in M.discrete_trajectories_active:  # loop over each discrete trajectory\n",
    "                tmp_.append(eigvec[dtraj_mapped])\n",
    "            proj_ev_all.append(np.hstack(tmp_))\n",
    "        return proj_ev_all\n",
    "\n",
    "    \n",
    "    proj_ev_all = proj_ev()\n",
    "    \n",
    "    ncols = 4; nrows = int(np.ceil(first_n_ev / float(ncols)))\n",
    "    plt.figure(figsize=(16,nrows*3))\n",
    "\n",
    "    vmin=-2\n",
    "    vmax=2\n",
    "\n",
    "    for i in range(first_n_ev):\n",
    "      if 1:\n",
    "        plt.figure(figsize=(9,3))\n",
    "\n",
    "      if 1:\n",
    "        plt.subplot(1, 3, 1)\n",
    "#        plot_sampled_function(tmp[:,0], tmp[:,1], np.vstack(proj_ev_all)[i], cbar=False, cmap='BrBG', vmin=vmin, vmax=vmax, nlevels=50)\n",
    "        plot_sampled_function(np.vstack(Y)[:,0], np.vstack(Y)[:,1], proj_ev_all[i], cbar=False, cmap='BrBG', vmin=vmin, vmax=vmax, nlevels=50)\n",
    "#        plot_sampled_function(tmp[:,0], tmp[:,1], (proj_ev_all), cbar=False, cmap='BrBG', vmin=vmin, vmax=vmax, nlevels=50)\n",
    "        plt.gca().set_aspect('equal')\n",
    "        plt.gca().set_axis_bgcolor('k')\n",
    "        plt.ylabel(i)\n",
    "\n",
    "      if 0:\n",
    "        plt.subplot(1, 3, 2)\n",
    "#        plot_sampled_function(tmp[:,0], tmp[:,2], np.vstack(proj_ev_all)[i], cbar=False, cmap='BrBG', vmin=vmin, vmax=vmax, nlevels=50)\n",
    "        plot_sampled_function(np.vstack(Y)[:,0], np.vstack(Y)[:,2], proj_ev_all[i], cbar=False, cmap='BrBG', vmin=vmin, vmax=vmax, nlevels=50)\n",
    "        plt.gca().set_aspect('equal')\n",
    "        plt.gca().set_axis_bgcolor('k')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plot_sampled_function(np.vstack(Y)[:,1], np.vstack(Y)[:,2], proj_ev_all[i], cbar=False, cmap='BrBG', vmin=vmin, vmax=vmax, nlevels=50)\n",
    "#        plot_sampled_function(tmp[:,1], tmp[:,2], np.vstack(proj_ev_all)[i], cbar=False, cmap='BrBG', vmin=vmin, vmax=vmax, nlevels=50)\n",
    "        plt.gca().set_aspect('equal')\n",
    "        plt.gca().set_axis_bgcolor('k')\n",
    "      if 1:\n",
    "        plt.figtext(0, .9, 'eig_{} = {}'.format(i, M.eigenvalues()[i]))\n",
    "        if i>0:\n",
    "            plt.figtext(0, .8, 'its_{} = {:.4f} ns'.format(i, dt*M.timescales()[i-1]))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('{}/eigenvec_lag{}_{:02d}.png'.format(activedir, msm_lag, i), dpi=144)\n",
    "    return\n",
    "\n",
    "\n",
    "plt.close('all')\n",
    "show_eigenvec(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCCA\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of desired macrostates\n",
    "n_sets = 10\n",
    "M.pcca(n_sets)\n",
    "\n",
    "pcca_dist = np.copy(M.metastable_distributions)  # P(state | metastable)\n",
    "pcca_dist = np.append(pcca_dist, np.zeros((n_sets,1)), axis=1)\n",
    "\n",
    "membership = np.copy(M.metastable_memberships)  # P(metastable | state)\n",
    "membership = np.append(membership, np.zeros((1,n_sets)), axis=0)\n",
    "\n",
    "# memberships over trajectory\n",
    "dist_all = [np.hstack([pcca_dist[i,:][dtraj_m] for dtraj_m in M.discrete_trajectories_active]) for i in range(n_sets)]\n",
    "mem_all = [np.hstack([membership[:,i][dtraj_m] for dtraj_m in M.discrete_trajectories_active]) for i in range(n_sets)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "meso_cc = np.where((clustering.clustercenters==(0,0)).all(axis=1))[0][0]\n",
    "\n",
    "plt.close('all')\n",
    "plt.plot(membership[meso_cc, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vargaslo/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:23: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18.18804137   8.32231577]\n",
      "[ 18.37121434  24.80010204]\n",
      "[ 20.52450965  11.44772921]\n",
      "[ 20.88108733   8.32018011]\n",
      "[ 21.16193359  32.98898012]\n",
      "[ 20.52538295   5.34191946]\n",
      "[ 20.86697368  24.68245319]\n",
      "[ 20.52986303  21.81132946]\n",
      "[ 20.51309969  27.95626363]\n",
      "[ 21.06042776  16.55682571]\n"
     ]
    }
   ],
   "source": [
    "def show_pcca_dens():\n",
    "\n",
    "    def get_centroid(clustercenters, weights):\n",
    "        active = np.copy(M.active_set)\n",
    "        sz = np.copy(clustercenters)\n",
    "        sz = sz[active, :]\n",
    "        \n",
    "        fz = sz[:,1] / 16.58  # [0,2)\n",
    "        fz_P = fz[np.argmax(weights)]  # fz value of highest probability\n",
    "\n",
    "        fz_lower = fz_P - 1\n",
    "        new_fz = (fz - fz_lower) % 2 + fz_lower\n",
    "                \n",
    "        new_z = new_fz * 16.58\n",
    "        \n",
    "        sz[:,1] = new_z\n",
    "\n",
    "        sz_w = sz * weights[:,np.newaxis]\n",
    "        \n",
    "        max_sz = np.sum(sz_w, axis=0)\n",
    "        print (max_sz)\n",
    "        return max_sz\n",
    "    \n",
    "    ncols = 3; nrows = int(np.ceil(n_sets*3 / float(ncols)))\n",
    "    ncols=2; nrows=1\n",
    "    plt.close('all')\n",
    "    plt.rc('font', size=10)\n",
    "    \n",
    "    vmin = 0\n",
    "    vmax = 100\n",
    "        \n",
    "    for i in range(n_sets):\n",
    "      if 1:\n",
    "        plt.figure(figsize=(5,5))\n",
    "        \n",
    "        # DIST\n",
    "        plt.subplot(1, ncols, 3*0+1)\n",
    "        plt.gca().set_axis_bgcolor('k')\n",
    "        plt.gca().set_aspect('equal')\n",
    "        plot_sampled_density(np.vstack(Y)[:,0], np.vstack(Y)[:,1], dist_all[i], nbins=300, vmin=0, cmap=cm.viridis, cbar=False)\n",
    "        scen, zcen = get_centroid(clustering.clustercenters, pcca_dist[i,0:-1])\n",
    "        plt.scatter(scen, zcen, c='r')\n",
    "        plt.ylabel('{} pcca_dist P(state|metastable) z={:.1f}'.format(i,zcen))\n",
    "        plt.xticks([17, 19, 21, 23])\n",
    "\n",
    "      if 1:\n",
    "        # MEMB\n",
    "        plt.subplot(1, ncols, 2)\n",
    "        plt.gca().set_axis_bgcolor('k')\n",
    "        plt.gca().set_aspect('equal')\n",
    "        plot_sampled_density(np.vstack(Y)[:,0], np.vstack(Y)[:,1], mem_all[i], nbins=300, vmin=0, cmap=cm.viridis, cbar=False)\n",
    "        #plt.scatter(*get_centroid(clustering.clustercenters, pcca_dist[i,0:-1]), c='r')\n",
    "        plt.ylabel('Membership -- P(metastable {})'.format(i))\n",
    "        plt.xticks([17, 19, 21, 23])\n",
    "      if 1:\n",
    "        plt.savefig('{}/eig_dens_lag{}_nsets{}_{:02d}.png'.format(activedir, msm_lag, n_sets, i), dpi=144)\n",
    "    return\n",
    "    \n",
    "\n",
    "#show_pcca_dens(np.swapaxes(Y,0,1))\n",
    "show_pcca_dens()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Chapman-Kolmogorov test\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "ck = M.cktest(n_sets, mlags=4, err_est=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    plt.close('all')\n",
    "    plt.figure()\n",
    "    mplt.plot_cktest(ck, diag=True, figsize=(16,8), layout=(4, 3), \n",
    "                 padding_top=0.1, y01=True, padding_between=0.15, dt=.001, units='ns')\n",
    "    plt.savefig('{}/cktest_nclust{}_lag{}_nsets{}.png'.format(activedir, n_clusters, msm_lag, n_sets), dpi=144)\n",
    "except:\n",
    "    print \"Figure not created\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coarse-grained kinetic Model using a Hidden Markov Model\n",
    "------\n",
    "\n",
    "Now we want a coarse-grained kinetic model between these four metastable states. Coarse-graining of Markov models has been investigated by a number of researchers, so different approaches exist. It is certainly a bad a idea to just bin the clusters into four groups, e.g. using the PCCA memberships, and then re-estimate an MSM on these four states. This is going to be a very poor MSM, most likely it will not get timescales anywhere near those seen above and fail the CK-Test.\n",
    "\n",
    "We recommend the following approach: Use the MSM and the metastable states computed by PCCA in order to estimate a four-state HMM. This can be simply achieved by calling coarse-grain on the MSM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "Lag time 10 is on the order of mean trajectory length3. It is recommended to fit four lag times in each trajectory. HMM might be inaccurate.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19.757179528317021"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print np.shape(M.transition_matrix)\n",
    "print ('Lag time ' + str(M.lag) + ' is on the order of mean trajectory length'\n",
    "                                + str(3) + '. It is recommended to fit four lag times in each '\n",
    "                                + 'trajectory. HMM might be inaccurate.')\n",
    "np.mean([_np.size(dtraj) for dtraj in dtrajs])\n",
    "np.mean([len(traj) for traj in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hidden Markov Model\n",
    "hmm = M.coarse_grain(n_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vargaslo/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:13: RuntimeWarning: divide by zero encountered in log10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.936678368649\n",
      "1 0 0.0\n",
      "2 0 0.00133299034786\n",
      "3 0 2.13000576957e-43\n",
      "4 0 9.82451648699e-134\n",
      "5 0 0.0011860260298\n",
      "6 0 0.0\n",
      "7 0 0.0\n",
      "8 0 0.0\n",
      "9 0 2.37170720047e-176\n",
      "0 1 0.0\n",
      "1 1 0.978154559605\n",
      "2 1 0.0\n",
      "3 1 0.0\n",
      "4 1 0.0\n",
      "5 1 0.0\n",
      "6 1 0.0\n",
      "7 1 0.0\n",
      "8 1 0.0\n",
      "9 1 0.0\n",
      "0 2 0.032694987709\n",
      "1 2 0.0\n",
      "2 2 0.99629975048\n",
      "3 2 0.00146046062924\n",
      "4 2 9.47346018697e-177\n",
      "5 2 3.77535863871e-44\n",
      "6 2 0.0\n",
      "7 2 0.0\n",
      "8 2 0.0\n",
      "9 2 2.47417224264e-37\n",
      "0 3 8.46819612139e-42\n",
      "1 3 0.0\n",
      "2 3 0.00236725917213\n",
      "3 3 0.987364298422\n",
      "4 3 0.00348746686885\n",
      "5 3 0.00226394334306\n",
      "6 3 3.71379226002e-235\n",
      "7 3 0.0\n",
      "8 3 0.0\n",
      "9 3 0.00345628376713\n",
      "0 4 4.30013865035e-132\n",
      "1 4 0.0\n",
      "2 4 1.69054109982e-176\n",
      "3 4 0.0038394696216\n",
      "4 4 0.992776278063\n",
      "5 4 0.000447586515208\n",
      "6 4 0.00322672571168\n",
      "7 4 5.47959043686e-198\n",
      "8 4 0.000397793908483\n",
      "9 4 1.6311049801e-142\n",
      "0 5 0.0306266436422\n",
      "1 5 0.0\n",
      "2 5 3.97474456822e-44\n",
      "3 5 0.00147048504141\n",
      "4 5 0.000264065038347\n",
      "5 5 0.996102444112\n",
      "6 5 0.0\n",
      "7 5 0.0\n",
      "8 5 0.0\n",
      "9 5 1.47973881735e-144\n",
      "0 6 0.0\n",
      "1 6 0.0\n",
      "2 6 0.0\n",
      "3 6 4.0254545529e-235\n",
      "4 6 0.00317686109033\n",
      "5 6 0.0\n",
      "6 6 0.990828447075\n",
      "7 6 0.000984316072467\n",
      "8 6 0.000541000649493\n",
      "9 6 0.0032224700204\n",
      "0 7 0.0\n",
      "1 7 0.00988687034458\n",
      "2 7 0.0\n",
      "3 7 0.0\n",
      "4 7 2.69525261532e-198\n",
      "5 7 0.0\n",
      "6 7 0.000491756124886\n",
      "7 7 0.998485123129\n",
      "8 7 0.000316378241059\n",
      "9 7 1.69214986116e-05\n",
      "0 8 0.0\n",
      "1 8 0.0119585700507\n",
      "2 8 0.0\n",
      "3 8 0.0\n",
      "4 8 0.000295328939792\n",
      "5 8 0.0\n",
      "6 8 0.0004079523964\n",
      "7 8 0.000477532691164\n",
      "8 8 0.998744827201\n",
      "9 8 6.55807162255e-183\n",
      "0 9 1.60011436181e-174\n",
      "1 9 0.0\n",
      "2 9 6.80558884142e-37\n",
      "3 9 0.00586528628577\n",
      "4 9 2.51420445609e-142\n",
      "5 9 3.866071067e-144\n",
      "6 9 0.00504511869169\n",
      "7 9 5.30281069655e-05\n",
      "8 9 1.36159188865e-182\n",
      "9 9 0.993304324714\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.patheffects as path_effects\n",
    "\n",
    "# View stationary distribution of states\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.bar([i-.25 for i in range(n_sets)], hmm.stationary_distribution, width=.5)\n",
    "\n",
    "# View transition matrix\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.log10(hmm.transition_matrix), cmap=cm.viridis, vmin=-4, vmax=0, interpolation='nearest')\n",
    "plt.gca().set_axis_bgcolor('k')\n",
    "# Label with values\n",
    "for i in range(n_sets):\n",
    "    for j in range(n_sets):\n",
    "        print j,i,hmm.transition_matrix[j,i]\n",
    "        if hmm.transition_matrix[j,i]>5e-4:\n",
    "            val = '{:.3f}'.format(hmm.transition_matrix[j,i])\n",
    "            text = plt.gca().text(i,j, val, color='white', ha='center', va='center', size=60//n_sets)\n",
    "            text.set_path_effects([path_effects.Stroke(linewidth=3, foreground='black'), path_effects.Normal()])\n",
    "\n",
    "plt.colorbar()\n",
    "\n",
    "plt.savefig('{}/pcca_clusters{}_lag{}_nsets{}.png'.format(activedir, n_clusters, msm_lag, n_sets), dpi=144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**forward committor**: \n",
      "[ 0.          1.          0.          0.          0.48066496  0.          1.\n",
      "  1.          1.          0.48380356]\n",
      "\n",
      "('Total TPT flux = ', 0.00064029065648358934)\n",
      "('Round trip time = ', 15617.907115682392)\n",
      "\n",
      "('A->B transition time = ', 7753.3565960115875)\n",
      "('B->A transition time = ', 7864.5505196717522)\n",
      "('Round trip time = ', 15617.90711568334)\n",
      "\n",
      "('mfpt(A,B) = ', 9814.0262117143757)\n",
      "('mfpt(B,A) = ', 12868.802464508764)\n",
      "Round trip time = 22682.8286762\n"
     ]
    }
   ],
   "source": [
    "A, B = [3], [5]\n",
    "#A, B = [4], [9]\n",
    "A,B = [0,2,3,5], [1, 6, 7, 8]\n",
    "\n",
    "\n",
    "tpt = msm.tpt(hmm, A,B)\n",
    "\n",
    "print ('**forward committor**: ')\n",
    "print (tpt.committor)\n",
    "\n",
    "#print ('Gross TPT flux = ', tpt.gross_flux)\n",
    "#print ('Net TPT flux = ', tpt.net_flux)\n",
    "print ('')\n",
    "print ('Total TPT flux = ', tpt.total_flux)\n",
    "print ('Round trip time = ', msm_lag/tpt.total_flux)\n",
    "\n",
    "#print ('Rate from TPT flux = ', tpt.rate)\\\n",
    "print ('')\n",
    "print ('A->B transition time = ', msm_lag/tpt.rate)\n",
    "print ('B->A transition time = ', msm_lag/msm.tpt(hmm, B,A).rate)\n",
    "print ('Round trip time = ', msm_lag/msm.tpt(hmm, A,B).rate+msm_lag/msm.tpt(hmm, B,A).rate)\n",
    "\n",
    "print ('')\n",
    "print ('mfpt(A,B) = ', hmm.mfpt(A,B))\n",
    "print ('mfpt(B,A) = ', hmm.mfpt(B,A))\n",
    "print ('Round trip time = {}'.format(np.sum((hmm.mfpt(B, A), hmm.mfpt(A,B)))))\n",
    "\n",
    "oneway = msm_lag/tpt.total_flux/2\n",
    "oneway_ = np.sum((hmm.mfpt(B, A), hmm.mfpt(A,B)))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.76013596421e-10 1.21191410438e-10\n"
     ]
    }
   ],
   "source": [
    "estD = 0.5*16.58**2/oneway * 1e-8  # m2/s\n",
    "estD_ = 0.5*16.58**2/oneway_ * 1e-8  # m2/s\n",
    "print estD,estD_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.        ]\n",
      " [ 1.          0.2       ]\n",
      " [ 0.          0.3       ]\n",
      " [ 0.          0.5       ]\n",
      " [ 0.48066496  0.4       ]\n",
      " [ 0.          0.9       ]\n",
      " [ 1.          0.1       ]\n",
      " [ 1.          0.6       ]\n",
      " [ 1.          0.7       ]\n",
      " [ 0.48380356  0.8       ]]\n",
      "\n",
      "**Gross flux illustration**: \n",
      "\n",
      "**Net flux illustration**: \n",
      "\n",
      "**Net percentage flux illustration**: \n"
     ]
    }
   ],
   "source": [
    "# we position states along the y-axis according to the commitor\n",
    "tptpos = np.array([tpt.committor, [\n",
    "                                   .0, # 0\n",
    "                                   .2, # 1\n",
    "                                   .3, # 2\n",
    "                                   .5, # 3\n",
    "                                   .4, # 4\n",
    "                                   .9, # 5\n",
    "                                   .1, # 6\n",
    "                                   .6, # 7\n",
    "                                   .7, # 8\n",
    "                                   .8, # 9\n",
    "                               #    0, # 10\n",
    "                               #    0, # 11\n",
    "                               #    0 # 12\n",
    "                                  ]]).transpose()\n",
    "\n",
    "tptpos =  np.array([tpt.committor, 1.0*np.arange(n_sets)[np.argsort(tpt.committor)]/n_sets]).transpose()\n",
    "print (tptpos)\n",
    "\n",
    "minflux = 1e-7\n",
    "\n",
    "plt.close('all')\n",
    "print ('\\n**Gross flux illustration**: ')\n",
    "#mplt.plot_flux(tpt, pos=tptpos, arrow_label_format=\"%10.1e\", attribute_to_plot='gross_flux', minflux=1e-5)\n",
    "mplt.plot_flux(tpt, pos=tptpos, arrow_label_format=\"%10.2e\", attribute_to_plot='gross_flux', minflux=minflux, fontsize=44)\n",
    "plt.savefig('{}/tpt_gross_flux_clusters{}_lag{}_A{}_B{}.png'.format(activedir, n_clusters, msm_lag, A, B), dpi=144)\n",
    "\n",
    "plt.close('all')\n",
    "print ('\\n**Net flux illustration**: ')\n",
    "mplt.plot_flux(tpt, pos=tptpos, arrow_label_format=\"%10.2e\", attribute_to_plot='net_flux', minflux=minflux, fontsize=44)\n",
    "plt.savefig('{}/tpt_net_flux_clusters{}_lag{}_A{}_B{}.png'.format(activedir, n_clusters, msm_lag, A, B), dpi=144)\n",
    "\n",
    "plt.close('all')\n",
    "print ('\\n**Net percentage flux illustration**: ')\n",
    "mplt.plot_flux(tpt, pos=tptpos, flux_scale=100.0/tpt.total_flux, arrow_label_format=\"%3.1f\", minflux=minflux, fontsize=44)\n",
    "plt.title('Estimated Dz from tpt rate: {:.2e} m2 s-1'.format(estD))\n",
    "plt.savefig('{}/tpt_pct_flux_clusters{}_lag{}_A{}_B{}.png'.format(activedir, n_clusters, msm_lag, A, B), dpi=144)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
